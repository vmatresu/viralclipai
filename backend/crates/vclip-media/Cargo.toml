[package]
name = "vclip-media"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
description = "FFmpeg CLI wrapper for video processing"

[features]
default = ["opencv"]
opencv = ["dep:opencv"]

[dependencies]
vclip-models = { workspace = true }

tokio = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
thiserror = { workspace = true }
tracing = { workspace = true }
which = { workspace = true }
tempfile = { workspace = true }
metrics = { workspace = true }
metrics-exporter-prometheus = { workspace = true }
uuid = { version = "1.0", features = ["v4"] }
async-trait = "0.1"
ndarray = "0.15"
image = "0.24"

# ONNX Runtime for face mesh landmark refinement
# - CUDA feature is optional; CPU-only still works when CUDA not present.
# - We use pre-downloaded binaries in onnxruntime-artifacts/ and set ORT_LIB_LOCATION
#   in the Dockerfile instead of download-binaries for reproducible builds.
# - Locally, enable download-binaries for development/testing
ort = { version = "2.0.0-rc.10", features = ["half", "download-binaries"], default-features = false }

# OpenCV for YuNet face detection (optional - falls back to FFmpeg if not available)
# Include imgcodecs so debug rendering can write overlays when enabled.
opencv = { version = "0.93", default-features = false, features = ["objdetect", "imgproc", "videoio", "dnn", "imgcodecs"], optional = true }

[dev-dependencies]
tokio-test = { workspace = true }
