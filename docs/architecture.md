# Architecture (Current Stack)

This document is the concise, up-to-date view of ViralClip AI. It replaces older drafts and reflects the current production-ready Rust-first implementation.

## System Overview

- **Backend**: Rust (Axum, Tokio) workspace under `backend/`
- **Worker**: Rust orchestrator (`processor.rs`) + modular `clip_pipeline` (tasks/scene/clip)
- **Media**: `vclip-media` (FFmpeg wrappers + style processors)
- **AI**: Google Gemini via `vclip-ml-client`
- **Queue**: Redis + Apalis (`vclip-queue`)
- **Storage**: Cloudflare R2 via `vclip-storage`
- **Metadata**: Firestore via `vclip-firestore`
- **Auth**: Firebase Auth; **Frontend**: Next.js App Router (TypeScript, Tailwind)

## Workspace Map (backend/)

```
crates/
  vclip-api        # Axum HTTP + WebSocket API
  vclip-worker     # Job orchestration & clip pipeline
  vclip-media      # FFmpeg + style engines (static & intelligent)
  vclip-storage    # R2 client/presigned URLs
  vclip-firestore  # Repositories for videos/clips
  vclip-ml-client  # Gemini client + prompts
  vclip-queue      # Redis/Apalis jobs
  vclip-models     # Shared types (Style, CropMode, EncodingConfig, etc.)
```

## Processing Orchestrator (`vclip-worker`)

- **Coordinator**: `processor.rs` (no legacy suffix). Responsibilities:
  - Download source video
  - Run Gemini transcript + highlight analysis
  - Write `highlights.json` to R2
  - Generate clip tasks (`clip_pipeline/tasks.rs`)
  - Parallel scene/clip execution (`clip_pipeline/scene.rs`, `clip_pipeline/clip.rs`)
  - Persist metadata to Firestore, upload artifacts to R2
  - Emit progress over Redis-backed channels
- **Resource safety**: shared semaphores for FFmpeg, sanitized commands, fail-fast on critical errors, continue-on-error per clip.

## Media & Styles (`vclip-media`)

- Static styles use shared `run_basic_style` (Original, Split, Left/Right focus) for DRY logging/metrics/thumbnails.
- `split_fast` uses FastSplit + thumbnails.
- Intelligent styles use tier-aware crop/split engines (YuNet + audio tiers) with FFmpeg rendering.
- Filters and encoding presets live in `vclip-media` (see `styles/` + `encoding.rs`).

## Storage & Metadata

- **R2 layout**: `{user_id}/{video_id}/highlights.json` + `clips/*.mp4/.jpg`
- **Firestore**: authoritative metadata for videos/clips; avoids R2 listing.
- **Presigned URLs**: generated by `vclip-storage` for secure access.

## API Surface (`vclip-api`)

- Axum routers for video/clip retrieval and WebSocket session for processing.
- Firebase ID token auth, CORS, rate limits, structured logging/metrics.
- Progress + status are streamed; API refuses clip access until `highlights.json` exists.

## Frontend (Next.js)

- App Router + React + TypeScript + Tailwind.
- Firebase auth; WebSocket client for progress; fetches metadata via API when processing completes.

## Observability & Security

- Structured tracing everywhere; metrics via `MetricsCollector`.
- FFmpeg/yt-dlp presence and resource limits checked; commands sanitized.
- Fail-fast on critical path; per-clip best-effort to maximize throughput.

## Read More

- `docs/video-processing-pipeline.md` – end-to-end pipeline phases
- `docs/STYLES_AND_CROP_MODES.md` – styles/crop modes
- `docs/logging-and-observability.md` – metrics/logging
- `docs/storage-and-media.md` – R2 layout and media rules
- `docs/plans-and-quotas.md` – plan tiers, clip quotas, and storage limits
